# üöÄ MODEL RETRAINING REPORT
**Datum:** 2025-11-02, 16:30 Uhr
**Anlass:** Vollst√§ndige Bar-Aggregation aus 3.3M historischen Ticks
**Status:** ‚úÖ **ABGESCHLOSSEN MIT GEMISCHTEN ERGEBNISSEN**

---

## üìä DATEN-UPGRADE

### Vorher (Erstes Training)
```
Bars pro Symbol:     251 (1m timeframe)
Gesamt Bars:       1,255
Training Samples:  ~1,225
Zeitraum:          2.3 Tage (teilweise)
```

### Nachher (Nach vollst√§ndiger Aggregation)
```
Bars pro Symbol:   1,075 (1m timeframe)  ‚úÖ +329%
Gesamt Bars:       5,375                 ‚úÖ +328%
Training Samples:  ~5,300                ‚úÖ +333%
Zeitraum:          2.3 Tage (vollst√§ndig)
```

### Tick-Daten Basis
```
EURUSD: 640,554 Ticks (3 Tabellen)
GBPUSD: 640,568 Ticks
USDJPY: 640,685 Ticks
USDCHF: 640,705 Ticks
AUDUSD: 640,553 Ticks

GESAMT: 3,342,850 Ticks ‚Üí 5,375 Bars
```

**Aggregationsrate:** ~622 Ticks pro Bar (durchschnittlich)

---

## ü§ñ MODEL PERFORMANCE COMPARISON

### Model 1: XGBoost (label_h5, 5min Horizon)

#### VORHER (251 Bars, 1,225 Samples)
```
Metric           Train    Val      Test
----------------------------------------
Accuracy         1.0000   0.7213   0.6973  ‚úÖ
Precision        1.0000   0.5000   0.4762
Recall           1.0000   0.0784   0.1818
F1-Score         1.0000   0.1356   0.2632
ROC-AUC          1.0000   0.5823   0.6453  ‚úÖ
```

#### NACHHER (1,075 Bars, 5,300 Samples)
```
Metric           Train    Val      Test
----------------------------------------
Accuracy         0.9936   0.7428   0.6600  ‚ö†Ô∏è -5.4%
Precision        1.0000   0.2857   0.3750  ‚ö†Ô∏è -21.2%
Recall           0.9756   0.0757   0.0690  ‚ùå -62.0%
F1-Score         0.9876   0.1197   0.1165  ‚ùå -55.7%
ROC-AUC          1.0000   0.5906   0.4989  ‚ùå -22.7%
```

**ANALYSE:**
- ‚ùå **Test Accuracy gesunken:** 69.7% ‚Üí 66.0%
- ‚ùå **ROC-AUC stark gesunken:** 0.645 ‚Üí 0.499 (fast Random!)
- ‚ùå **Recall deutlich schlechter:** 18.2% ‚Üí 6.9%
- ‚ö†Ô∏è **Overfitting bleibt:** Train Acc 99.4% vs Test 66%

**URSACHEN:**
1. **Class Imbalance versch√§rft:** Mehr Daten, aber nur 12.2% UP Labels
2. **Niedrige Volatilit√§t:** Die zus√§tzlichen Daten sind aus niedrig-volatilen Perioden
3. **Model lernt "immer DOWN predicten":** 87.8% DOWN Labels

---

### Model 2: LightGBM (label_h5, 5min Horizon)

#### VORHER
```
Metric           Train    Val      Test
----------------------------------------
Accuracy         1.0000   0.7213   0.7027  ‚úÖ
Precision        1.0000   0.5000   0.5000
Recall           1.0000   0.0392   0.0909
F1-Score         1.0000   0.0727   0.1538
ROC-AUC          1.0000   0.5401   0.6242  ‚úÖ
```

#### NACHHER
```
Metric           Train    Val      Test
----------------------------------------
Accuracy         0.9901   0.7516   0.6737  ‚ö†Ô∏è -4.1%
Precision        1.0000   0.2308   0.4783  ‚ö†Ô∏è -4.3%
Recall           0.9623   0.0324   0.0421  ‚ùå -53.7%
F1-Score         0.9808   0.0569   0.0775  ‚ùå -49.6%
ROC-AUC          0.9999   0.6113   0.5080  ‚ùå -18.6%
```

**ANALYSE:**
- ‚ö†Ô∏è **Test Accuracy leicht gesunken:** 70.3% ‚Üí 67.4%
- ‚ùå **ROC-AUC deutlich schlechter:** 0.624 ‚Üí 0.508
- ‚ö†Ô∏è **Recall halbiert:** 9.1% ‚Üí 4.2%

---

### Model 3: XGBoost (label_h10, 10min Horizon)

#### VORHER
```
Metric           Train    Val      Test
----------------------------------------
Accuracy         1.0000   0.6704   0.5778
Precision        1.0000   0.5000   0.7500
Recall           1.0000   0.0678   0.0750
F1-Score         1.0000   0.1194   0.1364
ROC-AUC          1.0000   0.5223   0.6155
```

#### NACHHER
```
Metric           Train    Val      Test
----------------------------------------
Accuracy         0.9968   0.6801   0.5727  ‚âà GLEICH
Precision        1.0000   0.2987   0.4821  ‚ùå -35.7%
Recall           0.9898   0.1027   0.0796  ‚âà GLEICH
F1-Score         0.9949   0.1528   0.1367  ‚âà GLEICH
ROC-AUC          1.0000   0.4785   0.5307  ‚ö†Ô∏è -13.8%
```

**ANALYSE:**
- ‚âà **Accuracy fast gleich:** 57.8% ‚Üí 57.3%
- ‚ùå **Precision deutlich schlechter:** 75% ‚Üí 48.2%
- ‚ö†Ô∏è **ROC-AUC gesunken:** 0.616 ‚Üí 0.531

---

## üìâ PERFORMANCE SUMMARY

### Vergleich: Alt vs Neu

| Metric | Model | Vorher | Nachher | Change | Bewertung |
|--------|-------|--------|---------|--------|-----------|
| **Accuracy** | XGBoost (h5) | 69.7% | 66.0% | -3.7% | ‚ö†Ô∏è SCHLECHTER |
| **Accuracy** | LightGBM (h5) | 70.3% | 67.4% | -2.9% | ‚ö†Ô∏è SCHLECHTER |
| **ROC-AUC** | XGBoost (h5) | 0.645 | 0.499 | -22.7% | ‚ùå VIEL SCHLECHTER |
| **ROC-AUC** | LightGBM (h5) | 0.624 | 0.508 | -18.6% | ‚ùå VIEL SCHLECHTER |
| **Precision** | XGBoost (h5) | 47.6% | 37.5% | -10.1% | ‚ùå SCHLECHTER |
| **Recall** | XGBoost (h5) | 18.2% | 6.9% | -11.3% | ‚ùå VIEL SCHLECHTER |

**GESAMT-BEWERTUNG:** ‚ùå **VERSCHLECHTERUNG**

---

## üîç PROBLEM-ANALYSE

### 1. Class Imbalance Problem versch√§rft

**Label Distribution (label_h5):**
```
Vorher (251 bars):   23.0% UP, 77.0% DOWN  (Balance: 0.30)
Nachher (1,075 bars): 12.2% UP, 87.8% DOWN  (Balance: 0.14)
```

**Ursache:** Die zus√§tzlichen 824 Bars enthalten noch weniger volatile Phasen!

**Effekt:**
- Model lernt "immer DOWN predicten" ‚Üí 87.8% Accuracy m√∂glich
- Aber: ROC-AUC nahe 0.5 (Random Guessing)
- Recall sehr niedrig (viele False Negatives)

### 2. Datenqualit√§t: Niedrig-volatile Perioden

Die zus√§tzlichen Daten stammen haupts√§chlich von:
- Nacht-Sessions (niedrige Liquidit√§t)
- Wochenend-Gaps
- Konsolidierungsphasen

**Konsequenz:**
- Weniger "echte" Trading-Signale
- Mehr Noise
- Schwierigeres Lernproblem

### 3. Overfitting bleibt bestehen

```
XGBoost Train Accuracy: 99.4%
XGBoost Test Accuracy:  66.0%

Differenz: 33.4% (massive Overfitting!)
```

**Ursache:**
- Zu viele Features (174 features)
- Zu tiefe Trees (max_depth=6)
- Keine ausreichende Regularisierung

---

## üí° L√ñSUNGSANS√ÑTZE

### Sofort-Ma√ünahmen

#### 1. Class Balancing implementieren
```python
# In Training Script:
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
# scale_pos_weight ‚âà 7.2 (f√ºr 12.2% UP)

xgb_params = {
    'scale_pos_weight': scale_pos_weight,  # NEU
    ...
}
```

#### 2. Threshold senken (wieder)
```json
{
  "min_profit_pips": 1.0  // Statt 1.5
}
```

**Erwartung:** Balance steigt auf ~0.25-0.30

#### 3. Regularisierung erh√∂hen
```python
xgb_params = {
    'max_depth': 4,           # Statt 6
    'min_child_weight': 5,    # Statt 1
    'gamma': 0.5,             # Statt 0
    'subsample': 0.7,         # Statt 0.8
    'learning_rate': 0.05,    # Statt 0.1
}
```

#### 4. Feature Selection
```python
# Nutze nur Top 30-50 wichtigste Features
# Statt alle 174 Features
```

### Mittelfristig

#### 5. Data Filtering
```python
# Filtere nur volatile Handelsphasen:
# - London Session (08:00-16:00 UTC)
# - NY Session (13:00-21:00 UTC)
# - Overlap (13:00-16:00 UTC) ‚Üê BESTE ZEIT

# Entferne:
# - Nacht-Sessions
# - Wochenenden
# - Niedrig-volatile Bars (ATR < Threshold)
```

#### 6. Alternative: Regression statt Classification
```python
# Predict: Prozentuale Preis√§nderung
# Statt: UP/DOWN Binary

# Vorteil: Keine Class Imbalance
# Nachteil: Komplexeres Model
```

---

## üìä VERGLEICH: WELCHES MODEL NUTZEN?

### Empfehlung: **ALTE MODELS BEHALTEN!** ‚úÖ

| Kriterium | Alte Models (251 bars) | Neue Models (1,075 bars) | Gewinner |
|-----------|----------------------|------------------------|----------|
| **Test Accuracy** | 69.7% | 66.0% | ‚úÖ ALT |
| **ROC-AUC** | 0.645 | 0.499 | ‚úÖ ALT |
| **Precision** | 47.6% | 37.5% | ‚úÖ ALT |
| **Recall** | 18.2% | 6.9% | ‚úÖ ALT |
| **F1-Score** | 0.263 | 0.117 | ‚úÖ ALT |
| **Trainingsdaten** | 1,225 | 5,300 | ‚úÖ NEU |

**Fazit:** Trotz 4.3x mehr Daten sind die **alten Models besser**!

**Grund:** Qualit√§t > Quantit√§t
- 251 Bars aus volatile Perioden > 1,075 Bars mit viel Noise

---

## üéØ AKTIONSPLAN

### Option A: Alte Models verwenden (EMPFOHLEN)
```bash
# Nutze die Models vom ersten Training
# models/xgboost_1m_label_h5_lookback5.model (erste Version)

# Diese sind bereits in Production!
```

**Begr√ºndung:**
- ‚úÖ Bessere Performance (69.7% Accuracy, 0.645 AUC)
- ‚úÖ Funktionierende Signal Generation (bereits getestet)
- ‚úÖ Keine weitere Arbeit n√∂tig

### Option B: Neue Models mit Fixes (2-3h Arbeit)
```bash
1. min_profit_pips auf 1.0 reduzieren
2. Labels neu generieren
3. Class Weights implementieren
4. Regularisierung erh√∂hen
5. Feature Selection
6. Neu trainieren
```

**Erwartung:**
- Accuracy: 66% ‚Üí 70-72%
- ROC-AUC: 0.50 ‚Üí 0.62-0.65
- Recall: 7% ‚Üí 15-25%

### Option C: Data Filtering + Retraining (4-6h Arbeit)
```bash
1. Filtere nur volatile Trading-Sessions
2. Entferne niedrig-liquide Perioden
3. Behalte nur ~500-600 beste Bars
4. Trainiere neu
```

**Erwartung:**
- Accuracy: 72-75%
- ROC-AUC: 0.65-0.70
- Recall: 20-30%

---

## üèÜ LEARNINGS

### Was haben wir gelernt?

#### 1. Mehr Daten ‚â† Bessere Models
- ‚ùå 4.3x mehr Daten f√ºhrte zu schlechteren Models
- ‚úÖ Qualit√§t der Daten ist wichtiger als Quantit√§t
- ‚úÖ Filtere gezielt volatile/liquide Perioden

#### 2. Class Imbalance ist kritisch
- ‚ùå 12% UP vs 88% DOWN ‚Üí Model lernt "DOWN predicten"
- ‚úÖ Threshold muss sorgf√§ltig gew√§hlt werden
- ‚úÖ Class Weights oder Balancing notwendig

#### 3. Overfitting bleibt Problem
- ‚ùå Train Acc 99% vs Test Acc 66% ‚Üí 33% Gap!
- ‚úÖ Mehr Regularisierung n√∂tig
- ‚úÖ Feature Selection kritisch

#### 4. ROC-AUC ist wichtigster Metric
- Accuracy kann t√§uschen (bei Imbalance)
- ROC-AUC zeigt echte pr√§diktive F√§higkeit
- 0.50 = Random, 0.65 = Gut, 0.80+ = Sehr gut

---

## üìã EMPFEHLUNG

### F√ºr Production: **ALTE MODELS NUTZEN** ‚úÖ

```
Model: XGBoost (label_h5, erste Version)
File: models/xgboost_1m_label_h5_lookback5.model (Backup anlegen!)
Performance: 69.7% Accuracy, 0.645 AUC

Begr√ºndung:
- Bessere Metriken als neue Models
- Bereits getestet & funktionsf√§hig
- Signal Generator nutzt diese bereits
```

### F√ºr Zukunft: **Data Quality verbessern**

```
1. Sammle Daten NUR w√§hrend:
   - London Session (08:00-16:00 UTC)
   - NY Session (13:00-21:00 UTC)
   - Overlap ‚Üê  BESTE (13:00-16:00 UTC)

2. Filtere:
   - ATR > Minimum Threshold (volatile genug)
   - Spread < Maximum (gute Liquidit√§t)
   - Keine Wochenenden/Feiertage

3. Target:
   - ~500-1,000 HOCHQUALITATIVE Bars
   - Statt 5,000+ mit viel Noise
```

---

## üìä FINAL STATUS

### Models Verf√ºgbar

**Version 1 (251 bars) - EMPFOHLEN:**
```
‚úÖ xgboost_1m_label_h5_lookback5.model (69.7% acc, 0.645 AUC)
‚úÖ lightgbm_1m_label_h5_lookback5.model (70.3% acc, 0.624 AUC)
```

**Version 2 (1,075 bars) - Backup:**
```
‚ö†Ô∏è xgboost_1m_label_h5_lookback5.model (66.0% acc, 0.499 AUC)
‚ö†Ô∏è lightgbm_1m_label_h5_lookback5.model (67.4% acc, 0.508 AUC)
```

### N√§chste Schritte

1. ‚úÖ **Nutze Version 1 Models** f√ºr Signal Generation
2. üìÖ **Implementiere Phase 4** (Automated Trading) mit guten Models
3. üìÖ **Sammle selektiv neue Daten** (nur volatile Sessions)
4. üìÖ **Iteriere** mit besseren Daten

---

**Report Ende**
**Status:** Models trainiert, aber Version 1 bleibt empfohlen
**Next Action:** Phase 4 mit alten (besseren) Models
